# BE-Project-Phase 1 Emotion recognition Using Machine Learning 
Mental health issue is prevalent in the current digital era. People often get dependent
on external factors to cope with stress, anxiety, depression, loneliness, etc. This
usually results in dependency on the substance. Socioeconomic conditions affect the
quality of human life. People living in underprivileged communities have low standards
and satisfaction with life due to poor socioeconomic status.
Lack of quality education and healthcare results in addiction problems in marginalized
communities. It is difficult to treat patients with substance dependency if it is
severe. The issue of substance dependence is a huge burden in the healthcare sector
and on the economy. Rehabilitation centres run by governments, non-profit organizations,
and for-profit organizations provide support to patients addicted to substances
which include alcohol, tobacco, etc. Health professionals treat patients in rehabilitation
with medical and psychological interventions. They monitor the admitted patients
throughout their healing journey by performing quantitative analysis to see changes
in behavioural and biological aspects.
The central objective of this project is to analyze the sentiments of the patients to
detect levels of substance dependency using artificial intelligence techniques. This
will provide quantitative insights to help healthcare professionals to monitor patients’
health throughout their treatment duration. We are developing a system to detect
the underlying emotions of patients in the recorded speech by analyzing the acoustic
features of the audio data of recordings by implementing an Artificial Neural Network
(ANN) method and comparing its results with the results of conventional methods.
The audio signals and their content are the input. These signals are analyzed to
detect emotions. The signal pre-processing is done before extracting audio features
that involve getting the dataset, importing libraries, importing the dataset, encoding
categorical data, and splitting the dataset into training, testing, and feature scaling.
iv
Feature extraction aims to reduce the number of features in a dataset by creating new
features from the existing ones (and then discarding the original features). We utilize
a spectrogram to visualize signals in a picture, which depicts time on the x-axis, frequency
on the y-axis, and amplitude on the x-axis for more comprehensive information.
It can also be in different hues, with the color density indicating the signal’s strength.
Finally, it provides a summary of the signal, describing how the signal’s strength is
divided among frequencies. The result from this analysis will be helpful to determine
changes in patients’ responses to the treatment through quantitative insights provided
by audio signals.
